# File: backend/agent/tools/document/processor.py
# Purpose: æ–‡æ¡£å¤„ç†å·¥å…·ï¼ˆæ‰¹é‡æ€»ç»“ã€æ–‡æœ¬æå–ç­‰ï¼‰
import concurrent.futures
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any

from agent.tools.validators import ensure_path_allowed, normalize_path


@dataclass
class BatchSummarizeDocumentsTool:
    """å¤šçº¿ç¨‹æ‰¹é‡æ€»ç»“å¤šä¸ªæ–‡æ¡£ï¼ˆPDF/Word/Excel/TXTç­‰ï¼‰å¹¶ä¿å­˜æ‘˜è¦åˆ°æœ¬åœ°"""

    name: str = "batch_summarize_documents"
    description: str = "å¤šçº¿ç¨‹æ‰¹é‡æ€»ç»“å¤šä¸ªæ–‡æ¡£ï¼ˆæ”¯æŒPDF/Word/Excel/TXTç­‰ï¼‰ï¼Œç”Ÿæˆæ‘˜è¦å¹¶ä¿å­˜åˆ°æŒ‡å®šä½ç½®"
    parameters: dict[str, Any] = None

    def __post_init__(self) -> None:
        if self.parameters is None:
            self.parameters = {
                "type": "object",
                "properties": {
                    "file_paths": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "è¦æ€»ç»“çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨",
                    },
                    "output_path": {
                        "type": "string",
                        "description": "ä¿å­˜æ‘˜è¦çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆMarkdownæ ¼å¼ï¼‰",
                    },
                    "max_workers": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 10,
                        "description": "æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°",
                    },
                    "summary_length": {
                        "type": "string",
                        "enum": ["short", "medium", "long"],
                        "description": "æ‘˜è¦é•¿åº¦ï¼šshort(ç®€çŸ­), medium(ä¸­ç­‰), long(è¯¦ç»†)",
                    },
                },
                "required": ["file_paths", "output_path"],
            }

    def _extract_text_from_file(self, file_path: Path) -> str:
        """ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹"""
        try:
            suffix = file_path.suffix.lower()

            # PDFæ–‡ä»¶
            if suffix == ".pdf":
                try:
                    import PyPDF2

                    with open(file_path, "rb") as f:
                        reader = PyPDF2.PdfReader(f)
                        text = ""
                        for page in reader.pages[:20]:  # é™åˆ¶å‰20é¡µ
                            text += page.extract_text() + "\n"
                        return text[:10000]  # é™åˆ¶å­—ç¬¦æ•°
                except Exception:
                    return "[PDFè§£æå¤±è´¥]"

            # Wordæ–‡æ¡£
            elif suffix in [".docx", ".doc"]:
                try:
                    import docx

                    doc = docx.Document(file_path)
                    text = "\n".join([para.text for para in doc.paragraphs[:100]])
                    return text[:10000]
                except Exception:
                    return "[Wordæ–‡æ¡£è§£æå¤±è´¥]"

            # Excelæ–‡ä»¶
            elif suffix in [".xlsx", ".xls"]:
                try:
                    import pandas as pd

                    df = pd.read_excel(file_path, nrows=100)
                    return df.to_string()[:10000]
                except Exception:
                    return "[Excelè§£æå¤±è´¥]"

            # çº¯æ–‡æœ¬æ–‡ä»¶
            elif suffix in [".txt", ".md", ".json", ".csv", ".log"]:
                with open(file_path, "r", encoding="utf-8", errors="replace") as f:
                    return f.read(10000)

            else:
                return f"[ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}]"

        except Exception as e:
            return f"[æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}]"

    def _generate_summary(self, text: str, length: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ‘˜è¦"""
        if not text or text.startswith("["):
            return text

        lines = text.split("\n")
        lines = [line.strip() for line in lines if line.strip()]

        # æ ¹æ®é•¿åº¦é€‰æ‹©æ‘˜è¦è¡Œæ•°
        length_map = {"short": 5, "medium": 15, "long": 30}
        max_lines = length_map.get(length, 15)

        # ç®€å•çš„æ‘˜è¦ç­–ç•¥ï¼šå–å‰Nè¡Œ + å…³é”®ä¿¡æ¯
        summary_lines = []
        word_count = 0

        for line in lines[:max_lines]:
            summary_lines.append(line)
            word_count += len(line)
            if word_count > 1000 and length == "short":
                break
            if word_count > 3000 and length == "medium":
                break

        summary = "\n".join(summary_lines)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats = f"\n\n**ç»Ÿè®¡**: æ€»å­—ç¬¦æ•°={len(text)}, æ€»è¡Œæ•°={len(lines)}"
        return summary + stats

    def _process_single_file(
        self, file_path_str: str, length: str
    ) -> tuple[str, str, bool]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            file_path = normalize_path(file_path_str)
            ensure_path_allowed(file_path)

            if not file_path.exists() or not file_path.is_file():
                return file_path_str, "[æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶]", False

            # æå–æ–‡æœ¬
            text = self._extract_text_from_file(file_path)

            # ç”Ÿæˆæ‘˜è¦
            summary = self._generate_summary(text, length)

            return file_path_str, summary, True

        except Exception as e:
            return file_path_str, f"[å¤„ç†å¤±è´¥: {str(e)}]", False

    def execute(self, args: dict[str, Any]) -> dict[str, Any]:
        file_paths = args.get("file_paths", [])
        output_path_str = args.get("output_path", "")
        max_workers = int(args.get("max_workers", 4))
        length = args.get("summary_length", "medium")

        if not file_paths:
            return {"ok": False, "error": "file_paths is required"}

        if not output_path_str:
            return {"ok": False, "error": "output_path is required"}

        try:
            output_path = normalize_path(output_path_str)
            ensure_path_allowed(output_path)

            # å¤šçº¿ç¨‹å¤„ç†æ–‡ä»¶
            results = []
            with concurrent.futures.ThreadPoolExecutor(
                max_workers=max_workers
            ) as executor:
                futures = [
                    executor.submit(self._process_single_file, fp, length)
                    for fp in file_paths
                ]

                for future in concurrent.futures.as_completed(futures):
                    results.append(future.result())

            # ç”ŸæˆMarkdownæŠ¥å‘Š
            report_lines = [
                "# æ–‡æ¡£æ‰¹é‡æ‘˜è¦æŠ¥å‘Š",
                f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                f"å¤„ç†æ–‡ä»¶æ•°: {len(file_paths)}",
                f"æ‘˜è¦é•¿åº¦: {length}",
                "\n---\n",
            ]

            success_count = 0
            for file_path, summary, success in results:
                if success:
                    success_count += 1

                report_lines.append(f"## ğŸ“„ {Path(file_path).name}\n")
                report_lines.append(f"**è·¯å¾„**: `{file_path}`\n")
                report_lines.append(f"**çŠ¶æ€**: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}\n")
                report_lines.append("**æ‘˜è¦**:\n")
                report_lines.append(f"```\n{summary}\n```\n")
                report_lines.append("\n---\n")

            report_lines.append(
                f"\n## ğŸ“Š æ€»ç»“\n\n- æ€»æ–‡ä»¶æ•°: {len(file_paths)}\n- æˆåŠŸ: {success_count}\n- å¤±è´¥: {len(file_paths) - success_count}"
            )

            report_content = "\n".join(report_lines)

            # ä¿å­˜æŠ¥å‘Š
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(report_content)

            return {
                "ok": True,
                "data": {
                    "output_file": str(output_path),
                    "total_files": len(file_paths),
                    "success_count": success_count,
                    "failed_count": len(file_paths) - success_count,
                },
            }

        except Exception as e:
            return {"ok": False, "error": f"æ‰¹é‡æ€»ç»“å¤±è´¥: {str(e)}"}


@dataclass
class ExtractTextFromDocumentsTool:
    """æ‰¹é‡ä»æ–‡æ¡£ä¸­æå–çº¯æ–‡æœ¬"""

    name: str = "extract_text_from_documents"
    description: str = "æ‰¹é‡ä»å¤šä¸ªæ–‡æ¡£ï¼ˆPDF/Word/Excelç­‰ï¼‰ä¸­æå–çº¯æ–‡æœ¬å†…å®¹"
    parameters: dict[str, Any] = None

    def __post_init__(self) -> None:
        if self.parameters is None:
            self.parameters = {
                "type": "object",
                "properties": {
                    "file_paths": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "æ–‡ä»¶è·¯å¾„åˆ—è¡¨",
                    },
                    "output_directory": {
                        "type": "string",
                        "description": "è¾“å‡ºç›®å½•ï¼ˆæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå¯¹åº”çš„.txtæ–‡ä»¶ï¼‰",
                    },
                },
                "required": ["file_paths", "output_directory"],
            }

    def execute(self, args: dict[str, Any]) -> dict[str, Any]:
        file_paths = args.get("file_paths", [])
        output_dir_str = args.get("output_directory", "")

        if not file_paths or not output_dir_str:
            return {"ok": False, "error": "file_paths and output_directory are required"}

        try:
            output_dir = normalize_path(output_dir_str)
            ensure_path_allowed(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)

            results = []
            for fp in file_paths:
                file_path = normalize_path(fp)
                ensure_path_allowed(file_path)

                # ä½¿ç”¨BatchSummarizeDocumentsToolçš„æå–é€»è¾‘
                tool = BatchSummarizeDocumentsTool()
                text = tool._extract_text_from_file(file_path)

                # ä¿å­˜ä¸ºtxt
                output_file = output_dir / f"{file_path.stem}.txt"
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(text)

                results.append({"file": str(file_path), "output": str(output_file)})

            return {"ok": True, "data": {"extracted_files": results}}

        except Exception as e:
            return {"ok": False, "error": f"æ–‡æœ¬æå–å¤±è´¥: {str(e)}"}
