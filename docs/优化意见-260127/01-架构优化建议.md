# MacJarvis 架构优化建议

> **文档版本**: v1.0
> **创建日期**: 2026-01-27
> **优化目标**: 生产级别 + 商业化

---

## 目录

1. [当前架构分析](#1-当前架构分析)
2. [微服务化改造](#2-微服务化改造)
3. [数据持久化架构](#3-数据持久化架构)
4. [分布式架构设计](#4-分布式架构设计)
5. [API 网关设计](#5-api-网关设计)
6. [消息队列引入](#6-消息队列引入)
7. [缓存架构设计](#7-缓存架构设计)
8. [可扩展性设计](#8-可扩展性设计)
9. [实施路线图](#9-实施路线图)

---

## 1. 当前架构分析

### 1.1 现有架构优势

✅ **清晰的分层设计**
- 前后端分离
- Agent 核心独立
- 工具系统模块化

✅ **现代化技术栈**
- FastAPI + React
- 流式响应
- 容器化部署

✅ **良好的代码组织**
- Protocol 模式
- 事件驱动
- 类型安全

### 1.2 现有架构瓶颈

⚠️ **单体应用限制**
- 所有功能耦合在一个服务中
- 无法独立扩展不同模块
- 资源利用不均衡

⚠️ **内存存储局限**
```python
# src/server/app.py
USER_STORE: dict[str, User] = {}  # 重启丢失，无法横向扩展
```

⚠️ **无状态管理**
- 会话数据易丢失
- 无法多实例部署
- 缺乏持久化

⚠️ **工具执行阻塞**
- 工具同步执行可能阻塞主线程
- 长时间任务影响其他请求
- 无法并行处理多个用户请求

---

## 2. 微服务化改造

### 2.1 服务拆分方案

#### 建议的微服务架构

```
┌─────────────────────────────────────────────────────────────────┐
│                         API Gateway                              │
│                    (Kong / APISIX / Nginx)                       │
│                     - 路由                                        │
│                     - 认证/授权                                  │
│                     - 限流                                        │
│                     - 监控                                        │
└────────┬──────────────┬──────────────┬────────────┬─────────────┘
         │              │              │            │
    ┌────▼────┐   ┌────▼────┐   ┌────▼────┐  ┌───▼────┐
    │  User   │   │ Agent   │   │  Tool   │  │Session │
    │ Service │   │ Service │   │ Service │  │Service │
    │         │   │         │   │         │  │        │
    │- 注册   │   │- LLM调用│   │- 工具执行│  │- 会话  │
    │- 登录   │   │- 流式处理│   │- 命令运行│  │- 消息  │
    │- 权限   │   │- 事件生成│   │- 结果返回│  │- 历史  │
    └────┬────┘   └────┬────┘   └────┬────┘  └───┬────┘
         │              │              │           │
         └──────────────┴──────────────┴───────────┘
                            │
                    ┌───────▼────────┐
                    │  Message Bus   │
                    │   (RabbitMQ/   │
                    │     Kafka)     │
                    └───────┬────────┘
                            │
         ┌──────────────────┼──────────────────┐
         │                  │                  │
    ┌────▼────┐      ┌─────▼─────┐     ┌─────▼──────┐
    │ MongoDB │      │   Redis   │     │PostgreSQL  │
    │         │      │           │     │            │
    │- 会话数据│      │- 缓存     │     │- 用户数据  │
    │- 消息    │      │- 会话状态 │     │- 订阅信息  │
    └─────────┘      └───────────┘     └────────────┘
```

### 2.2 服务详细设计

#### **User Service (用户服务)**

**职责**:
- 用户注册、登录、认证
- 权限管理（RBAC）
- 订阅管理
- 用量统计

**技术栈**:
- FastAPI
- PostgreSQL (用户数据)
- JWT 认证
- bcrypt 密码加密

**API 示例**:
```python
POST   /api/v1/users/register
POST   /api/v1/users/login
GET    /api/v1/users/me
PUT    /api/v1/users/me
GET    /api/v1/users/me/usage
GET    /api/v1/users/me/subscription
```

**数据模型**:
```python
@dataclass
class User:
    id: str
    email: str
    password_hash: str
    created_at: datetime
    subscription_tier: str  # free, pro, enterprise
    api_quota: int
    api_used: int
    permissions: list[str]
```

---

#### **Agent Service (智能体服务)**

**职责**:
- LLM API 调用
- 流式响应生成
- 工具调用协调
- 事件流管理

**技术栈**:
- FastAPI
- Redis (状态管理)
- OpenAI SDK
- SSE (Server-Sent Events)

**API 示例**:
```python
POST   /api/v1/agent/chat           # 流式对话
POST   /api/v1/agent/chat/sync      # 同步对话
GET    /api/v1/agent/models         # 可用模型列表
POST   /api/v1/agent/cancel/{id}    # 取消执行中的任务
```

**关键改进**:
```python
class AgentService:
    async def process_stream(
        self,
        user_id: str,
        session_id: str,
        message: str,
        model: str
    ) -> AsyncIterator[AgentEvent]:
        # 1. 从 Session Service 获取历史
        history = await self.session_client.get_history(session_id)

        # 2. 构建消息
        messages = self._build_messages(history, message)

        # 3. 调用 LLM (异步流式)
        async for event in self.llm_client.stream_chat(messages):
            if event.type == "tool_call":
                # 4. 发送工具调用请求到 MQ
                await self.mq.publish("tool_queue", {
                    "tool_name": event.name,
                    "args": event.args,
                    "callback_id": event.id
                })
                yield ToolStartEvent(...)
            elif event.type == "content":
                yield ContentEvent(...)

        # 5. 保存消息到 Session Service
        await self.session_client.save_message(session_id, ...)
```

---

#### **Tool Service (工具服务)**

**职责**:
- 工具异步执行
- 命令运行
- 结果回调
- 工具注册管理

**技术栈**:
- Celery / RQ (任务队列)
- Redis (结果存储)
- Docker (沙箱隔离)

**架构设计**:
```python
class ToolService:
    def __init__(self, redis: Redis, mq: MessageBus):
        self.registry = ToolRegistry()
        self.executor = ToolExecutor()
        self.redis = redis
        self.mq = mq

    async def start_worker(self):
        """启动工具执行 Worker"""
        async for message in self.mq.consume("tool_queue"):
            task_id = message["callback_id"]
            try:
                # 异步执行工具
                result = await self.executor.execute(
                    name=message["tool_name"],
                    args=message["args"],
                    timeout=60
                )

                # 发送结果到 Agent Service
                await self.mq.publish("tool_result_queue", {
                    "task_id": task_id,
                    "result": result
                })
            except Exception as e:
                await self.mq.publish("tool_result_queue", {
                    "task_id": task_id,
                    "error": str(e)
                })
```

**工具沙箱隔离**:
```python
class SandboxedToolExecutor:
    """使用 Docker 容器隔离工具执行"""

    async def execute(self, tool_name: str, args: dict) -> dict:
        # 1. 创建临时容器
        container = await self.docker.containers.create(
            image="macjarvis-tool-sandbox",
            command=["python", "-m", "tool_runner", tool_name],
            mem_limit="512m",
            cpu_quota=50000,
            network_mode="none",  # 禁用网络（可选）
            remove=True
        )

        # 2. 启动并等待结果
        await container.start()
        result = await container.wait(timeout=60)

        # 3. 读取输出
        logs = await container.logs()
        return json.loads(logs)
```

---

#### **Session Service (会话服务)**

**职责**:
- 会话管理
- 消息存储
- 历史查询
- 上下文管理

**技术栈**:
- FastAPI
- MongoDB (消息存储)
- Redis (热数据缓存)

**API 示例**:
```python
POST   /api/v1/sessions                    # 创建会话
GET    /api/v1/sessions                    # 获取用户所有会话
GET    /api/v1/sessions/{id}               # 获取会话详情
DELETE /api/v1/sessions/{id}               # 删除会话
GET    /api/v1/sessions/{id}/messages      # 获取消息历史
POST   /api/v1/sessions/{id}/messages      # 添加消息
PUT    /api/v1/sessions/{id}/title         # 更新标题
```

**数据模型**:
```python
@dataclass
class Session:
    id: str
    user_id: str
    title: str
    created_at: datetime
    updated_at: datetime
    message_count: int
    model: str

@dataclass
class Message:
    id: str
    session_id: str
    role: str  # user, assistant, tool
    content: str
    tool_calls: list[dict] | None
    timestamp: datetime
```

**MongoDB 存储优化**:
```python
# 使用 MongoDB 的嵌套文档存储消息，提升查询性能
{
    "_id": "session_123",
    "user_id": "user_456",
    "title": "系统优化建议",
    "created_at": ISODate("2026-01-27T10:00:00Z"),
    "updated_at": ISODate("2026-01-27T10:30:00Z"),
    "messages": [
        {
            "id": "msg_1",
            "role": "user",
            "content": "查看系统信息",
            "timestamp": ISODate("2026-01-27T10:00:00Z")
        },
        {
            "id": "msg_2",
            "role": "assistant",
            "content": "正在查询...",
            "tool_calls": [{"name": "system_info", "args": {}}],
            "timestamp": ISODate("2026-01-27T10:00:05Z")
        }
    ]
}
```

---

### 2.3 服务间通信

#### **同步通信 (HTTP/gRPC)**

适用场景：需要立即响应的请求

```python
# User Service → Session Service
class UserService:
    def __init__(self, session_client: SessionServiceClient):
        self.session_client = session_client

    async def delete_user(self, user_id: str):
        # 1. 删除用户数据
        await self.db.delete_user(user_id)

        # 2. 同步调用 Session Service 删除所有会话
        await self.session_client.delete_user_sessions(user_id)
```

**建议使用 gRPC**:
- 性能更好（二进制协议）
- 强类型检查
- 双向流支持

```protobuf
// session.proto
service SessionService {
    rpc CreateSession(CreateSessionRequest) returns (Session);
    rpc GetMessages(GetMessagesRequest) returns (stream Message);
    rpc DeleteUserSessions(DeleteUserSessionsRequest) returns (Empty);
}
```

#### **异步通信 (消息队列)**

适用场景：耗时任务、事件通知

```python
# Agent Service → Tool Service (异步)
class AgentService:
    async def handle_tool_call(self, tool_call: dict):
        # 发布到消息队列，不等待结果
        await self.mq.publish("tool_execution", {
            "tool_name": tool_call["name"],
            "args": tool_call["args"],
            "callback_url": f"/agent/callback/{tool_call['id']}"
        })
```

**消息格式标准**:
```python
@dataclass
class Message:
    id: str                    # 消息 ID
    type: str                  # 消息类型
    payload: dict              # 消息体
    timestamp: datetime        # 时间戳
    retry_count: int           # 重试次数
    ttl: int                   # 过期时间（秒）
```

---

### 2.4 服务发现与注册

#### **使用 Consul / Etcd**

```python
# service_registry.py
class ServiceRegistry:
    def __init__(self, consul_url: str):
        self.consul = consul.Consul(host=consul_url)

    def register(
        self,
        service_name: str,
        service_id: str,
        address: str,
        port: int
    ):
        """注册服务"""
        self.consul.agent.service.register(
            name=service_name,
            service_id=service_id,
            address=address,
            port=port,
            check=consul.Check.http(
                f"http://{address}:{port}/health",
                interval="10s",
                timeout="5s"
            )
        )

    def discover(self, service_name: str) -> list[str]:
        """发现服务实例"""
        _, services = self.consul.health.service(
            service_name,
            passing=True  # 只返回健康的实例
        )
        return [
            f"http://{s['Service']['Address']}:{s['Service']['Port']}"
            for s in services
        ]
```

**客户端负载均衡**:
```python
class ServiceClient:
    def __init__(self, registry: ServiceRegistry):
        self.registry = registry
        self.cache = {}
        self.cache_ttl = 30  # 秒

    async def call(self, service_name: str, path: str, **kwargs):
        # 1. 获取服务实例列表（带缓存）
        instances = self._get_instances(service_name)

        # 2. 负载均衡选择（轮询/随机/最少连接）
        instance = random.choice(instances)

        # 3. 发起请求
        async with httpx.AsyncClient() as client:
            return await client.post(f"{instance}{path}", **kwargs)
```

---

### 2.5 微服务化收益

✅ **独立扩展**
- Tool Service 可以独立增加实例处理高负载工具执行
- Agent Service 可以根据 LLM 请求量扩展
- Session Service 可以根据存储需求扩展

✅ **技术栈灵活**
- Tool Service 可以用 Go 重写以提升性能
- Session Service 可以选择最适合的数据库

✅ **故障隔离**
- Tool Service 崩溃不影响 Agent Service
- 每个服务独立部署和回滚

✅ **团队协作**
- 不同团队负责不同服务
- 独立开发、测试、部署

---

## 3. 数据持久化架构

### 3.1 数据分类与存储选型

| 数据类型 | 当前方案 | 建议方案 | 理由 |
|---------|---------|---------|------|
| **用户数据** | 无 | PostgreSQL | ACID 保证，关系型数据 |
| **会话数据** | 内存 | MongoDB | 灵活 schema，高写入性能 |
| **消息历史** | 内存 | MongoDB | 文档存储，易于查询 |
| **缓存数据** | 无 | Redis | 高性能，会话状态 |
| **文件存储** | 本地 | S3 / MinIO | 分布式，高可用 |
| **日志数据** | 文件 | Elasticsearch | 全文搜索，聚合分析 |
| **指标数据** | 无 | Prometheus + InfluxDB | 时序数据，监控告警 |

### 3.2 PostgreSQL 设计 (用户与订阅)

#### **Schema 设计**

```sql
-- 用户表
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    display_name VARCHAR(100),
    avatar_url TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    last_login_at TIMESTAMP,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    is_verified BOOLEAN NOT NULL DEFAULT FALSE,
    CONSTRAINT email_format CHECK (email ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$')
);

-- 订阅计划表
CREATE TABLE subscription_plans (
    id SERIAL PRIMARY KEY,
    name VARCHAR(50) UNIQUE NOT NULL,  -- free, pro, enterprise
    display_name VARCHAR(100) NOT NULL,
    price_monthly DECIMAL(10, 2) NOT NULL,
    price_yearly DECIMAL(10, 2) NOT NULL,
    api_quota_daily INT NOT NULL,      -- 每日 API 调用次数
    max_sessions INT NOT NULL,         -- 最大会话数
    max_tools INT NOT NULL,            -- 可用工具数量
    features JSONB NOT NULL,           -- 功能列表
    is_active BOOLEAN NOT NULL DEFAULT TRUE
);

-- 用户订阅表
CREATE TABLE user_subscriptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    plan_id INT NOT NULL REFERENCES subscription_plans(id),
    status VARCHAR(20) NOT NULL,       -- active, canceled, expired
    started_at TIMESTAMP NOT NULL,
    expires_at TIMESTAMP,
    auto_renew BOOLEAN NOT NULL DEFAULT TRUE,
    payment_method VARCHAR(50),        -- stripe, alipay, wechat
    CONSTRAINT valid_status CHECK (status IN ('active', 'canceled', 'expired', 'trial'))
);

-- API 使用记录表（用于限流和统计）
CREATE TABLE api_usage (
    id BIGSERIAL PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    endpoint VARCHAR(100) NOT NULL,
    method VARCHAR(10) NOT NULL,
    status_code INT NOT NULL,
    response_time_ms INT NOT NULL,
    tokens_used INT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- 分区表（按日期分区）
CREATE TABLE api_usage_2026_01 PARTITION OF api_usage
    FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- 索引优化
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_user_subscriptions_user_id ON user_subscriptions(user_id);
CREATE INDEX idx_api_usage_user_created ON api_usage(user_id, created_at DESC);
```

#### **数据访问层 (Repository Pattern)**

```python
class UserRepository:
    def __init__(self, db: AsyncEngine):
        self.db = db

    async def create(self, user: UserCreate) -> User:
        async with self.db.begin() as conn:
            result = await conn.execute(
                insert(users).values(
                    email=user.email,
                    password_hash=hash_password(user.password)
                ).returning(users)
            )
            return User.from_orm(result.fetchone())

    async def get_by_email(self, email: str) -> User | None:
        async with self.db.begin() as conn:
            result = await conn.execute(
                select(users).where(users.c.email == email)
            )
            row = result.fetchone()
            return User.from_orm(row) if row else None

    async def get_usage_today(self, user_id: str) -> int:
        """获取今日 API 使用量"""
        async with self.db.begin() as conn:
            result = await conn.execute(
                select(func.count(api_usage.c.id))
                .where(
                    api_usage.c.user_id == user_id,
                    api_usage.c.created_at >= func.date_trunc('day', func.now())
                )
            )
            return result.scalar()
```

---

### 3.3 MongoDB 设计 (会话与消息)

#### **数据模型**

```javascript
// sessions 集合
{
    _id: "session_abc123",
    user_id: "user_456",
    title: "系统优化讨论",
    model: "gpt-4o-mini",
    created_at: ISODate("2026-01-27T10:00:00Z"),
    updated_at: ISODate("2026-01-27T10:30:00Z"),
    message_count: 15,
    last_message_at: ISODate("2026-01-27T10:30:00Z"),
    metadata: {
        tags: ["optimization", "system"],
        is_pinned: false,
        is_archived: false
    },

    // 嵌套消息（限制最近 50 条）
    messages: [
        {
            _id: "msg_1",
            role: "user",
            content: "帮我查看系统信息",
            timestamp: ISODate("2026-01-27T10:00:00Z"),
            tokens: 8
        },
        {
            _id: "msg_2",
            role: "assistant",
            content: "好的，正在查询系统信息...",
            tool_calls: [
                {
                    id: "call_123",
                    name: "system_info",
                    args: {}
                }
            ],
            timestamp: ISODate("2026-01-27T10:00:05Z"),
            tokens: 120
        },
        {
            _id: "msg_3",
            role: "tool",
            tool_call_id: "call_123",
            name: "system_info",
            content: "{\"os\": \"macOS\", \"version\": \"14.2\"}",
            timestamp: ISODate("2026-01-27T10:00:08Z")
        }
    ]
}

// 历史消息归档集合（messages 超过 50 条后归档）
{
    _id: "archive_session_abc123_page_1",
    session_id: "session_abc123",
    page: 1,
    messages: [/* 旧消息 */],
    created_at: ISODate("2026-01-27T09:00:00Z")
}
```

#### **索引设计**

```javascript
// sessions 集合索引
db.sessions.createIndex({ user_id: 1, updated_at: -1 });  // 用户会话列表
db.sessions.createIndex({ user_id: 1, "metadata.is_archived": 1 });  // 过滤归档
db.sessions.createIndex({ "messages.timestamp": -1 });  // 消息时间排序

// 消息归档集合索引
db.message_archives.createIndex({ session_id: 1, page: 1 });
```

#### **数据访问层**

```python
from motor.motor_asyncio import AsyncIOMotorClient

class SessionRepository:
    def __init__(self, mongo: AsyncIOMotorClient):
        self.db = mongo.macjarvis
        self.sessions = self.db.sessions
        self.archives = self.db.message_archives

    async def create_session(self, user_id: str, model: str) -> str:
        """创建新会话"""
        session = {
            "_id": f"session_{generate_id()}",
            "user_id": user_id,
            "title": "新对话",
            "model": model,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow(),
            "message_count": 0,
            "messages": [],
            "metadata": {"is_pinned": False, "is_archived": False}
        }
        await self.sessions.insert_one(session)
        return session["_id"]

    async def add_message(
        self,
        session_id: str,
        message: dict
    ) -> None:
        """添加消息到会话"""
        # 1. 检查消息数量
        session = await self.sessions.find_one({"_id": session_id})
        if len(session.get("messages", [])) >= 50:
            # 归档旧消息
            await self._archive_messages(session_id, session["messages"][:25])
            # 只保留最近 25 条
            await self.sessions.update_one(
                {"_id": session_id},
                {"$set": {"messages": session["messages"][25:]}}
            )

        # 2. 添加新消息
        await self.sessions.update_one(
            {"_id": session_id},
            {
                "$push": {"messages": message},
                "$set": {
                    "updated_at": datetime.utcnow(),
                    "last_message_at": message["timestamp"]
                },
                "$inc": {"message_count": 1}
            }
        )

    async def get_messages(
        self,
        session_id: str,
        limit: int = 50,
        before_id: str | None = None
    ) -> list[dict]:
        """获取消息历史（支持分页）"""
        session = await self.sessions.find_one({"_id": session_id})
        messages = session.get("messages", [])

        # 如果需要更早的消息，从归档中加载
        if before_id and len(messages) < limit:
            archived = await self._load_archived_messages(session_id)
            messages = archived + messages

        return messages[-limit:]

    async def _archive_messages(self, session_id: str, messages: list[dict]):
        """归档消息"""
        # 计算归档页码
        count = await self.archives.count_documents({"session_id": session_id})
        page = count + 1

        await self.archives.insert_one({
            "_id": f"archive_{session_id}_page_{page}",
            "session_id": session_id,
            "page": page,
            "messages": messages,
            "created_at": datetime.utcnow()
        })
```

---

### 3.4 Redis 缓存设计

#### **缓存策略**

| 数据类型 | 缓存 Key | TTL | 缓存策略 |
|---------|---------|-----|---------|
| 用户信息 | `user:{user_id}` | 1小时 | Cache-Aside |
| 会话列表 | `user:{user_id}:sessions` | 5分钟 | Write-Through |
| 会话详情 | `session:{session_id}` | 10分钟 | Cache-Aside |
| API 配额 | `quota:{user_id}:{date}` | 1天 | Write-Through |
| 工具结果 | `tool:{tool_name}:{hash}` | 1小时 | Cache-Aside |
| 在线用户 | `online_users` | - | Set |

#### **实现示例**

```python
class CacheService:
    def __init__(self, redis: Redis):
        self.redis = redis

    async def get_user(self, user_id: str) -> User | None:
        """获取用户信息（带缓存）"""
        # 1. 尝试从缓存读取
        cached = await self.redis.get(f"user:{user_id}")
        if cached:
            return User.parse_raw(cached)

        # 2. 从数据库加载
        user = await self.user_repo.get_by_id(user_id)
        if user:
            # 3. 写入缓存
            await self.redis.setex(
                f"user:{user_id}",
                3600,  # 1小时
                user.json()
            )
        return user

    async def check_quota(self, user_id: str) -> bool:
        """检查 API 配额（Redis 计数器）"""
        key = f"quota:{user_id}:{date.today()}"
        count = await self.redis.incr(key)

        # 首次设置过期时间
        if count == 1:
            await self.redis.expire(key, 86400)  # 24小时

        # 获取用户配额限制
        user = await self.get_user(user_id)
        return count <= user.subscription.api_quota_daily

    async def cache_tool_result(
        self,
        tool_name: str,
        args: dict,
        result: dict
    ) -> None:
        """缓存工具执行结果（幂等工具）"""
        # 只缓存只读工具的结果
        if tool_name in ["system_info", "disk_usage", "process_list"]:
            key = f"tool:{tool_name}:{hash_dict(args)}"
            await self.redis.setex(key, 3600, json.dumps(result))
```

---

### 3.5 对象存储设计 (S3 / MinIO)

#### **用途**

- 用户上传的文件
- 工具生成的输出文件
- 日志归档
- 导出数据

#### **目录结构**

```
macjarvis-storage/
├── users/
│   ├── {user_id}/
│   │   ├── uploads/           # 用户上传
│   │   │   ├── 2026/01/27/
│   │   │   │   └── file_abc123.txt
│   │   └── exports/           # 导出文件
│   │       └── sessions_export_2026_01_27.json
│
├── tool_outputs/
│   ├── {session_id}/
│   │   └── {tool_call_id}.json
│
└── logs/
    └── 2026/01/27/
        ├── agent_service.log.gz
        └── tool_service.log.gz
```

#### **实现示例**

```python
from aioboto3 import Session

class StorageService:
    def __init__(self, s3_config: S3Config):
        self.session = Session()
        self.bucket = s3_config.bucket
        self.endpoint = s3_config.endpoint

    async def upload_file(
        self,
        file_path: str,
        object_key: str,
        content_type: str = "application/octet-stream"
    ) -> str:
        """上传文件到 S3"""
        async with self.session.client('s3', endpoint_url=self.endpoint) as s3:
            await s3.upload_file(
                file_path,
                self.bucket,
                object_key,
                ExtraArgs={'ContentType': content_type}
            )
            return f"s3://{self.bucket}/{object_key}"

    async def get_presigned_url(
        self,
        object_key: str,
        expires_in: int = 3600
    ) -> str:
        """生成预签名 URL（用于前端直接下载）"""
        async with self.session.client('s3', endpoint_url=self.endpoint) as s3:
            url = await s3.generate_presigned_url(
                'get_object',
                Params={'Bucket': self.bucket, 'Key': object_key},
                ExpiresIn=expires_in
            )
            return url
```

---

## 4. 分布式架构设计

### 4.1 水平扩展策略

#### **无状态服务设计**

所有服务必须设计为无状态，状态存储在外部：

```python
# ❌ 错误：状态存储在内存
class AgentService:
    def __init__(self):
        self.active_sessions = {}  # 多实例时状态不一致

    def process(self, session_id: str, message: str):
        self.active_sessions[session_id] = message

# ✅ 正确：状态存储在 Redis
class AgentService:
    def __init__(self, redis: Redis):
        self.redis = redis

    async def process(self, session_id: str, message: str):
        await self.redis.setex(
            f"session:{session_id}:state",
            3600,
            message
        )
```

#### **负载均衡配置**

```nginx
# Nginx 配置
upstream agent_service {
    least_conn;  # 最少连接算法
    server agent-1:8000 weight=1 max_fails=3 fail_timeout=30s;
    server agent-2:8000 weight=1 max_fails=3 fail_timeout=30s;
    server agent-3:8000 weight=1 max_fails=3 fail_timeout=30s;

    keepalive 32;  # 连接池
}

upstream tool_service {
    ip_hash;  # 相同 IP 路由到同一实例（会话亲和性）
    server tool-1:8001;
    server tool-2:8001;
}

server {
    listen 80;

    location /api/agent/ {
        proxy_pass http://agent_service;
        proxy_http_version 1.1;
        proxy_set_header Connection "";

        # SSE 支持
        proxy_buffering off;
        proxy_cache off;
        proxy_set_header X-Accel-Buffering no;
    }

    location /api/tool/ {
        proxy_pass http://tool_service;
    }
}
```

---

### 4.2 分布式事务处理

#### **Saga 模式**

适用于跨多个服务的业务流程：

```python
class CreateUserSaga:
    """用户注册 Saga（跨 User Service 和 Session Service）"""

    async def execute(self, user_data: dict) -> dict:
        compensations = []

        try:
            # Step 1: 创建用户账号
            user = await self.user_service.create_user(user_data)
            compensations.append(
                lambda: self.user_service.delete_user(user.id)
            )

            # Step 2: 创建默认会话
            session = await self.session_service.create_session(
                user_id=user.id,
                title="欢迎使用 MacJarvis"
            )
            compensations.append(
                lambda: self.session_service.delete_session(session.id)
            )

            # Step 3: 发送欢迎邮件
            await self.email_service.send_welcome(user.email)

            return {"ok": True, "user": user, "session": session}

        except Exception as e:
            # 补偿操作（回滚）
            for compensate in reversed(compensations):
                try:
                    await compensate()
                except Exception as comp_error:
                    logger.error(f"Compensation failed: {comp_error}")

            return {"ok": False, "error": str(e)}
```

#### **分布式锁**

使用 Redis 实现分布式锁，防止并发问题：

```python
class DistributedLock:
    def __init__(self, redis: Redis):
        self.redis = redis

    async def acquire(
        self,
        key: str,
        timeout: int = 10,
        blocking_timeout: int = 5
    ) -> bool:
        """获取锁"""
        lock_key = f"lock:{key}"
        lock_value = str(uuid.uuid4())

        end_time = time.time() + blocking_timeout
        while time.time() < end_time:
            # 使用 SET NX EX 原子操作
            acquired = await self.redis.set(
                lock_key,
                lock_value,
                ex=timeout,
                nx=True
            )
            if acquired:
                return lock_value
            await asyncio.sleep(0.1)

        return None

    async def release(self, key: str, lock_value: str):
        """释放锁（使用 Lua 脚本保证原子性）"""
        lua_script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        await self.redis.eval(lua_script, 1, f"lock:{key}", lock_value)

# 使用示例
async def process_payment(user_id: str):
    lock = DistributedLock(redis)
    lock_value = await lock.acquire(f"payment:{user_id}", timeout=30)

    if not lock_value:
        raise Exception("无法获取锁，请稍后重试")

    try:
        # 执行支付逻辑
        await perform_payment(user_id)
    finally:
        await lock.release(f"payment:{user_id}", lock_value)
```

---

### 4.3 分布式会话管理

#### **Redis Session Store**

```python
class DistributedSessionStore:
    """分布式会话存储"""

    def __init__(self, redis: Redis):
        self.redis = redis
        self.ttl = 3600  # 1小时

    async def create_session(self, user_id: str) -> str:
        """创建会话"""
        session_id = f"sess_{uuid.uuid4().hex}"
        session_data = {
            "user_id": user_id,
            "created_at": datetime.utcnow().isoformat(),
            "last_accessed": datetime.utcnow().isoformat()
        }

        await self.redis.setex(
            f"session:{session_id}",
            self.ttl,
            json.dumps(session_data)
        )
        return session_id

    async def get_session(self, session_id: str) -> dict | None:
        """获取会话（自动续期）"""
        data = await self.redis.get(f"session:{session_id}")
        if not data:
            return None

        session = json.loads(data)
        session["last_accessed"] = datetime.utcnow().isoformat()

        # 续期
        await self.redis.setex(
            f"session:{session_id}",
            self.ttl,
            json.dumps(session)
        )
        return session

    async def invalidate_session(self, session_id: str):
        """销毁会话"""
        await self.redis.delete(f"session:{session_id}")
```

---

### 4.4 多数据中心部署

#### **主从架构**

```
┌─────────────────────────────────────────────────┐
│              Global Load Balancer               │
│              (Cloudflare / AWS Route53)         │
│                      ↓                           │
│         地理位置路由 + 健康检查                  │
└─────────────┬───────────────────────────────────┘
              │
    ┌─────────┴─────────┐
    │                   │
    ▼                   ▼
┌────────────┐    ┌────────────┐
│  US West   │    │  US East   │
│  (Primary) │    │ (Secondary)│
│            │    │            │
│ - API GW   │───▶│ - API GW   │ (数据同步)
│ - Services │    │ - Services │
│ - DB       │    │ - DB       │
└────────────┘    └────────────┘
```

#### **数据同步策略**

1. **PostgreSQL 主从复制**
```yaml
# docker-compose.yml
services:
  postgres-primary:
    image: postgres:16
    environment:
      POSTGRES_REPLICATION_MODE: master
    volumes:
      - pg-data-primary:/var/lib/postgresql/data

  postgres-replica:
    image: postgres:16
    environment:
      POSTGRES_REPLICATION_MODE: slave
      POSTGRES_MASTER_HOST: postgres-primary
    volumes:
      - pg-data-replica:/var/lib/postgresql/data
```

2. **MongoDB 副本集**
```javascript
rs.initiate({
  _id: "macjarvis-rs",
  members: [
    { _id: 0, host: "mongo1:27017", priority: 2 },  // Primary
    { _id: 1, host: "mongo2:27017", priority: 1 },  // Secondary
    { _id: 2, host: "mongo3:27017", priority: 1 }   // Secondary
  ]
});
```

3. **Redis 哨兵模式**
```python
from redis.sentinel import Sentinel

sentinel = Sentinel([
    ('sentinel1', 26379),
    ('sentinel2', 26379),
    ('sentinel3', 26379)
], socket_timeout=0.1)

# 自动故障转移
master = sentinel.master_for('mymaster', socket_timeout=0.1)
slave = sentinel.slave_for('mymaster', socket_timeout=0.1)

# 写主库
await master.set('key', 'value')
# 读从库
value = await slave.get('key')
```

---

## 5. API 网关设计

### 5.1 网关功能

| 功能 | 说明 | 实现方式 |
|------|------|---------|
| **路由** | 请求转发到后端服务 | Kong / APISIX |
| **认证** | JWT / OAuth2 验证 | 插件 |
| **授权** | RBAC 权限检查 | 自定义插件 |
| **限流** | API 调用频率限制 | Token Bucket |
| **熔断** | 故障服务隔离 | Circuit Breaker |
| **重试** | 失败请求自动重试 | Retry Plugin |
| **监控** | 请求日志、指标收集 | Prometheus + Grafana |
| **缓存** | 响应缓存 | Redis |
| **协议转换** | HTTP → gRPC | Protocol Adapter |

### 5.2 Kong 配置示例

#### **服务注册**

```yaml
# kong.yml
services:
  - name: agent-service
    url: http://agent-service:8000
    routes:
      - name: agent-chat
        paths:
          - /api/v1/agent/chat
        methods:
          - POST
        plugins:
          - name: jwt
          - name: rate-limiting
            config:
              minute: 60
              hour: 1000
          - name: request-size-limiting
            config:
              allowed_payload_size: 10  # MB

  - name: session-service
    url: http://session-service:8002
    routes:
      - name: sessions
        paths:
          - /api/v1/sessions
        methods:
          - GET
          - POST
        plugins:
          - name: jwt
          - name: cors
            config:
              origins:
                - "*"
```

#### **自定义插件 - 配额检查**

```lua
-- quota-checker.lua
local function check_quota(conf)
  local user_id = kong.request.get_header("X-User-ID")
  if not user_id then
    return kong.response.exit(401, { message = "User ID required" })
  end

  -- 从 Redis 检查配额
  local redis = require "resty.redis"
  local red = redis:new()
  red:connect("redis", 6379)

  local key = "quota:" .. user_id .. ":" .. os.date("%Y-%m-%d")
  local count = red:incr(key)

  if count == 1 then
    red:expire(key, 86400)  -- 24小时过期
  end

  -- 获取用户配额限制
  local limit_key = "user:" .. user_id .. ":quota_limit"
  local limit = red:get(limit_key) or 100

  if tonumber(count) > tonumber(limit) then
    return kong.response.exit(429, {
      message = "API quota exceeded",
      limit = limit,
      used = count,
      reset_at = os.date("%Y-%m-%d", os.time() + 86400)
    })
  end

  -- 设置响应头
  kong.response.set_header("X-RateLimit-Limit", limit)
  kong.response.set_header("X-RateLimit-Remaining", limit - count)
end

return {
  [kong.PLUGIN_PRIORITY.ACCESS] = check_quota
}
```

---

### 5.3 认证与授权

#### **JWT 认证流程**

```
1. 用户登录 → User Service
   ↓
2. 验证成功 → 生成 JWT Token
   ↓
3. 返回 Token 给前端
   ↓
4. 前端请求 API 时携带 Token
   ↓
5. API Gateway 验证 Token
   ↓
6. 验证成功 → 提取 user_id，转发到后端服务
   ↓
7. 后端服务处理请求
```

#### **Token 生成**

```python
import jwt
from datetime import datetime, timedelta

class AuthService:
    def __init__(self, secret_key: str):
        self.secret_key = secret_key

    def generate_token(
        self,
        user_id: str,
        expires_in: int = 86400  # 24小时
    ) -> str:
        """生成 JWT Token"""
        payload = {
            "user_id": user_id,
            "exp": datetime.utcnow() + timedelta(seconds=expires_in),
            "iat": datetime.utcnow(),
            "type": "access"
        }
        return jwt.encode(payload, self.secret_key, algorithm="HS256")

    def generate_refresh_token(self, user_id: str) -> str:
        """生成刷新 Token（有效期 30 天）"""
        payload = {
            "user_id": user_id,
            "exp": datetime.utcnow() + timedelta(days=30),
            "iat": datetime.utcnow(),
            "type": "refresh"
        }
        return jwt.encode(payload, self.secret_key, algorithm="HS256")

    def verify_token(self, token: str) -> dict | None:
        """验证 Token"""
        try:
            payload = jwt.decode(
                token,
                self.secret_key,
                algorithms=["HS256"]
            )
            return payload
        except jwt.ExpiredSignatureError:
            raise AuthError("Token expired")
        except jwt.InvalidTokenError:
            raise AuthError("Invalid token")
```

#### **RBAC 权限模型**

```python
@dataclass
class Permission:
    resource: str  # sessions, tools, admin
    action: str    # read, write, delete, execute

@dataclass
class Role:
    name: str      # free_user, pro_user, admin
    permissions: list[Permission]

# 角色定义
ROLES = {
    "free_user": Role(
        name="free_user",
        permissions=[
            Permission("sessions", "read"),
            Permission("sessions", "write"),
            Permission("tools", "execute"),  # 仅限基础工具
        ]
    ),
    "pro_user": Role(
        name="pro_user",
        permissions=[
            Permission("sessions", "read"),
            Permission("sessions", "write"),
            Permission("sessions", "delete"),
            Permission("tools", "execute"),  # 所有工具
            Permission("exports", "create"),
        ]
    ),
    "admin": Role(
        name="admin",
        permissions=[
            Permission("*", "*"),  # 所有权限
        ]
    )
}

# 权限检查中间件
async def check_permission(
    request: Request,
    resource: str,
    action: str
):
    user = request.state.user
    role = ROLES.get(user.role)

    for perm in role.permissions:
        if (perm.resource == "*" or perm.resource == resource) and \
           (perm.action == "*" or perm.action == action):
            return True

    raise HTTPException(403, "Permission denied")
```

---

## 6. 消息队列引入

### 6.1 使用场景

| 场景 | 队列类型 | 说明 |
|------|---------|------|
| **工具异步执行** | 任务队列 | 工具调用不阻塞主线程 |
| **事件通知** | 发布/订阅 | 服务间事件广播 |
| **日志收集** | 流式队列 | 实时日志聚合 |
| **延迟任务** | 延迟队列 | 定时清理、提醒 |
| **数据同步** | CDC 队列 | 数据库变更同步 |

### 6.2 RabbitMQ 设计

#### **队列拓扑**

```
                    ┌─────────────────┐
                    │  Tool Exchange  │
                    │   (topic)       │
                    └────────┬────────┘
                             │
        ┌────────────────────┼────────────────────┐
        │                    │                    │
   ┌────▼────┐        ┌─────▼─────┐       ┌─────▼─────┐
   │  tool.  │        │   tool.   │       │   tool.   │
   │  file   │        │  system   │       │  network  │
   │  queue  │        │   queue   │       │   queue   │
   └────┬────┘        └─────┬─────┘       └─────┬─────┘
        │                   │                    │
   ┌────▼────┐        ┌─────▼─────┐       ┌─────▼─────┐
   │ Worker  │        │  Worker   │       │  Worker   │
   │ Pool 1  │        │  Pool 2   │       │  Pool 3   │
   └─────────┘        └───────────┘       └───────────┘
```

#### **生产者代码**

```python
import aio_pika

class MessageProducer:
    def __init__(self, rabbitmq_url: str):
        self.url = rabbitmq_url
        self.connection = None
        self.channel = None

    async def connect(self):
        """建立连接"""
        self.connection = await aio_pika.connect_robust(self.url)
        self.channel = await self.connection.channel()

        # 声明 exchange
        self.exchange = await self.channel.declare_exchange(
            "tool_exchange",
            aio_pika.ExchangeType.TOPIC,
            durable=True
        )

    async def publish_tool_task(
        self,
        tool_name: str,
        args: dict,
        callback_id: str,
        priority: int = 5
    ):
        """发布工具执行任务"""
        message_body = {
            "tool_name": tool_name,
            "args": args,
            "callback_id": callback_id,
            "timestamp": datetime.utcnow().isoformat()
        }

        message = aio_pika.Message(
            body=json.dumps(message_body).encode(),
            content_type="application/json",
            delivery_mode=aio_pika.DeliveryMode.PERSISTENT,
            priority=priority,
            headers={
                "x-retry-count": 0,
                "x-max-retries": 3
            }
        )

        # 根据工具类型路由到不同队列
        routing_key = f"tool.{self._get_tool_category(tool_name)}"
        await self.exchange.publish(message, routing_key=routing_key)

    def _get_tool_category(self, tool_name: str) -> str:
        """根据工具名称确定分类"""
        file_tools = ["read_file", "write_file", "list_directory"]
        system_tools = ["system_info", "process_list", "disk_usage"]
        network_tools = ["network_info", "open_ports"]

        if tool_name in file_tools:
            return "file"
        elif tool_name in system_tools:
            return "system"
        elif tool_name in network_tools:
            return "network"
        else:
            return "general"
```

#### **消费者代码**

```python
class ToolWorker:
    def __init__(
        self,
        rabbitmq_url: str,
        queue_name: str,
        tool_executor: ToolExecutor
    ):
        self.url = rabbitmq_url
        self.queue_name = queue_name
        self.executor = tool_executor

    async def start(self):
        """启动 Worker"""
        connection = await aio_pika.connect_robust(self.url)
        channel = await connection.channel()

        # 设置 QoS（每次只处理 5 个消息）
        await channel.set_qos(prefetch_count=5)

        # 声明队列
        queue = await channel.declare_queue(
            self.queue_name,
            durable=True,
            arguments={
                "x-max-priority": 10,  # 支持优先级
                "x-message-ttl": 600000,  # 10分钟过期
                "x-dead-letter-exchange": "dlx_exchange"  # 死信队列
            }
        )

        # 开始消费
        async with queue.iterator() as queue_iter:
            async for message in queue_iter:
                async with message.process():
                    await self._process_message(message)

    async def _process_message(self, message: aio_pika.IncomingMessage):
        """处理消息"""
        try:
            body = json.loads(message.body.decode())

            # 执行工具
            result = await self.executor.execute(
                name=body["tool_name"],
                args=body["args"],
                timeout=60
            )

            # 发送结果到回调队列
            await self._send_callback(body["callback_id"], result)

        except Exception as e:
            logger.error(f"Tool execution failed: {e}")

            # 重试逻辑
            retry_count = message.headers.get("x-retry-count", 0)
            max_retries = message.headers.get("x-max-retries", 3)

            if retry_count < max_retries:
                # 重新发布消息（延迟重试）
                await self._retry_message(message, retry_count + 1)
            else:
                # 发送到死信队列
                logger.error(f"Max retries exceeded for {body['tool_name']}")

    async def _retry_message(self, message: aio_pika.IncomingMessage, retry_count: int):
        """延迟重试"""
        delay = min(2 ** retry_count, 60)  # 指数退避，最多 60 秒

        await asyncio.sleep(delay)

        # 重新发布消息
        new_message = aio_pika.Message(
            body=message.body,
            headers={
                **message.headers,
                "x-retry-count": retry_count
            }
        )
        await message.channel.default_exchange.publish(
            new_message,
            routing_key=message.routing_key
        )
```

---

### 6.3 事件驱动架构

#### **事件定义**

```python
@dataclass
class Event:
    id: str
    type: str
    source: str
    data: dict
    timestamp: datetime
    version: str = "1.0"

# 事件类型
class EventType:
    USER_REGISTERED = "user.registered"
    SESSION_CREATED = "session.created"
    MESSAGE_SENT = "message.sent"
    TOOL_EXECUTED = "tool.executed"
    SUBSCRIPTION_UPGRADED = "subscription.upgraded"
```

#### **事件发布**

```python
class EventPublisher:
    def __init__(self, mq: MessageBus):
        self.mq = mq

    async def publish(self, event: Event):
        """发布事件"""
        await self.mq.publish(
            exchange="events",
            routing_key=event.type,
            message={
                "id": event.id,
                "type": event.type,
                "source": event.source,
                "data": event.data,
                "timestamp": event.timestamp.isoformat(),
                "version": event.version
            }
        )

# 使用示例
async def create_user(user_data: dict):
    user = await user_repo.create(user_data)

    # 发布事件
    await event_publisher.publish(Event(
        id=generate_id(),
        type=EventType.USER_REGISTERED,
        source="user-service",
        data={"user_id": user.id, "email": user.email},
        timestamp=datetime.utcnow()
    ))
```

#### **事件订阅**

```python
class EventSubscriber:
    def __init__(self, mq: MessageBus):
        self.mq = mq
        self.handlers = {}

    def subscribe(self, event_type: str, handler: Callable):
        """注册事件处理器"""
        self.handlers[event_type] = handler

    async def start(self):
        """启动订阅"""
        async for event in self.mq.consume(exchange="events"):
            handler = self.handlers.get(event["type"])
            if handler:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Event handler failed: {e}")

# Session Service 订阅用户注册事件
subscriber = EventSubscriber(mq)

@subscriber.subscribe(EventType.USER_REGISTERED)
async def on_user_registered(event: dict):
    """用户注册后自动创建欢迎会话"""
    user_id = event["data"]["user_id"]

    session_id = await session_service.create_session(
        user_id=user_id,
        title="欢迎使用 MacJarvis"
    )

    await session_service.add_message(
        session_id=session_id,
        message={
            "role": "assistant",
            "content": "你好！我是 MacJarvis，你的 macOS 智能助手。有什么可以帮你的吗？",
            "timestamp": datetime.utcnow()
        }
    )
```

---

## 7. 缓存架构设计

### 7.1 多层缓存

```
┌─────────────────┐
│  Application    │
│  Memory Cache   │  ← L1: 进程内缓存（最快）
│  (LRU Cache)    │
└────────┬────────┘
         │ Miss
         ▼
┌─────────────────┐
│  Redis Cache    │  ← L2: 分布式缓存（快）
│  (Cluster)      │
└────────┬────────┘
         │ Miss
         ▼
┌─────────────────┐
│  Database       │  ← L3: 持久化存储（慢）
│  (PostgreSQL/   │
│   MongoDB)      │
└─────────────────┘
```

#### **实现示例**

```python
from functools import lru_cache
from typing import TypeVar, Callable

T = TypeVar('T')

class MultiLevelCache:
    def __init__(self, redis: Redis, l1_size: int = 1000):
        self.redis = redis
        self.l1_size = l1_size

    def cached(
        self,
        key_prefix: str,
        ttl: int = 3600,
        use_l1: bool = True
    ):
        """多层缓存装饰器"""
        def decorator(func: Callable[..., T]) -> Callable[..., T]:
            # L1 缓存（LRU）
            if use_l1:
                func = lru_cache(maxsize=self.l1_size)(func)

            async def wrapper(*args, **kwargs) -> T:
                # 构建缓存 key
                cache_key = f"{key_prefix}:{hash_args(args, kwargs)}"

                # L2: 尝试从 Redis 获取
                cached_value = await self.redis.get(cache_key)
                if cached_value:
                    return json.loads(cached_value)

                # L3: 调用原始函数
                result = await func(*args, **kwargs)

                # 写入 Redis
                await self.redis.setex(
                    cache_key,
                    ttl,
                    json.dumps(result)
                )

                return result

            return wrapper
        return decorator

# 使用示例
cache = MultiLevelCache(redis)

@cache.cached(key_prefix="user", ttl=3600)
async def get_user(user_id: str) -> User:
    """获取用户（三层缓存）"""
    return await db.query(User).filter_by(id=user_id).first()
```

---

### 7.2 缓存更新策略

#### **Cache-Aside (旁路缓存)**

```python
async def get_session(session_id: str) -> Session:
    # 1. 尝试从缓存读取
    cached = await redis.get(f"session:{session_id}")
    if cached:
        return Session.parse_raw(cached)

    # 2. 从数据库加载
    session = await db.sessions.find_one({"_id": session_id})
    if not session:
        raise NotFound("Session not found")

    # 3. 写入缓存
    await redis.setex(
        f"session:{session_id}",
        600,  # 10分钟
        json.dumps(session)
    )
    return Session(**session)

async def update_session(session_id: str, data: dict):
    # 1. 更新数据库
    await db.sessions.update_one(
        {"_id": session_id},
        {"$set": data}
    )

    # 2. 删除缓存（让下次读取时重新加载）
    await redis.delete(f"session:{session_id}")
```

#### **Write-Through (写穿透)**

```python
async def create_session(user_id: str, title: str) -> str:
    session = {
        "_id": generate_id(),
        "user_id": user_id,
        "title": title,
        "created_at": datetime.utcnow()
    }

    # 1. 写入数据库
    await db.sessions.insert_one(session)

    # 2. 同时写入缓存
    await redis.setex(
        f"session:{session['_id']}",
        600,
        json.dumps(session)
    )

    return session["_id"]
```

#### **Write-Behind (异步写回)**

```python
class WriteBehindCache:
    def __init__(self, redis: Redis, db: Database):
        self.redis = redis
        self.db = db
        self.write_queue = asyncio.Queue()

    async def set(self, key: str, value: dict):
        """写入缓存，异步写入数据库"""
        # 1. 立即写入缓存
        await self.redis.setex(key, 3600, json.dumps(value))

        # 2. 加入写队列
        await self.write_queue.put((key, value))

    async def background_writer(self):
        """后台写入线程"""
        while True:
            try:
                key, value = await self.write_queue.get()

                # 批量写入（每 100 条或每秒）
                batch = [value]
                try:
                    for _ in range(99):
                        batch.append(
                            await asyncio.wait_for(
                                self.write_queue.get(),
                                timeout=1.0
                            )
                        )
                except asyncio.TimeoutError:
                    pass

                # 批量写入数据库
                await self.db.bulk_insert(batch)

            except Exception as e:
                logger.error(f"Background write failed: {e}")
```

---

### 7.3 缓存穿透、击穿、雪崩防护

#### **缓存穿透防护（布隆过滤器）**

```python
from pybloom_live import BloomFilter

class CacheWithBloomFilter:
    def __init__(self, redis: Redis, capacity: int = 1000000):
        self.redis = redis
        self.bloom = BloomFilter(capacity=capacity, error_rate=0.001)

    async def get(self, key: str) -> dict | None:
        # 1. 布隆过滤器检查（快速判断 key 不存在）
        if key not in self.bloom:
            return None

        # 2. 从 Redis 获取
        cached = await self.redis.get(key)
        if cached:
            return json.loads(cached)

        # 3. 从数据库加载
        value = await self.db.get(key)
        if value:
            await self.set(key, value)
        return value

    async def set(self, key: str, value: dict):
        # 写入缓存
        await self.redis.setex(key, 3600, json.dumps(value))
        # 添加到布隆过滤器
        self.bloom.add(key)
```

#### **缓存击穿防护（互斥锁）**

```python
async def get_with_mutex(key: str) -> dict:
    """使用互斥锁防止缓存击穿"""
    # 1. 尝试从缓存获取
    cached = await redis.get(key)
    if cached:
        return json.loads(cached)

    # 2. 获取锁
    lock_key = f"lock:{key}"
    lock = await redis.set(lock_key, "1", ex=10, nx=True)

    if lock:
        try:
            # 3. 从数据库加载
            value = await db.get(key)

            # 4. 写入缓存
            if value:
                await redis.setex(key, 3600, json.dumps(value))
            else:
                # 空值缓存（防止穿透）
                await redis.setex(key, 60, "null")

            return value
        finally:
            # 5. 释放锁
            await redis.delete(lock_key)
    else:
        # 等待其他线程加载完成
        await asyncio.sleep(0.1)
        return await get_with_mutex(key)
```

#### **缓存雪崩防护（随机 TTL）**

```python
import random

async def set_with_random_ttl(key: str, value: dict, base_ttl: int = 3600):
    """设置随机 TTL 防止缓存雪崩"""
    # TTL 在 base_ttl ± 20% 范围内随机
    ttl = int(base_ttl * (0.8 + random.random() * 0.4))
    await redis.setex(key, ttl, json.dumps(value))
```

---

## 8. 可扩展性设计

### 8.1 插件系统

#### **工具插件架构**

```python
# plugin_system.py
class PluginManager:
    def __init__(self):
        self.plugins: dict[str, Tool] = {}

    def register_plugin(self, plugin: Tool):
        """注册插件"""
        if plugin.name in self.plugins:
            raise ValueError(f"Plugin {plugin.name} already registered")

        # 验证插件
        self._validate_plugin(plugin)

        self.plugins[plugin.name] = plugin
        logger.info(f"Registered plugin: {plugin.name}")

    def load_plugins_from_directory(self, directory: str):
        """从目录加载插件"""
        for file in Path(directory).glob("*.py"):
            spec = importlib.util.spec_from_file_location(file.stem, file)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            # 查找 Tool 类
            for name, obj in inspect.getmembers(module):
                if inspect.isclass(obj) and issubclass(obj, Tool) and obj != Tool:
                    self.register_plugin(obj())

    def _validate_plugin(self, plugin: Tool):
        """验证插件"""
        assert hasattr(plugin, "name"), "Plugin must have 'name'"
        assert hasattr(plugin, "description"), "Plugin must have 'description'"
        assert hasattr(plugin, "parameters"), "Plugin must have 'parameters'"
        assert callable(plugin.execute), "Plugin must have 'execute' method"

# 使用示例
plugin_manager = PluginManager()

# 加载内置工具
plugin_manager.load_plugins_from_directory("src/agent/tools/builtin")

# 加载用户自定义工具
plugin_manager.load_plugins_from_directory("/Users/username/.macjarvis/plugins")
```

#### **第三方工具示例**

```python
# ~/.macjarvis/plugins/slack_tool.py
from macjarvis import Tool

@dataclass
class SlackTool(Tool):
    name: str = "send_slack_message"
    description: str = "Send a message to Slack channel"
    parameters: dict = field(default_factory=lambda: {
        "type": "object",
        "properties": {
            "channel": {"type": "string", "description": "Channel name"},
            "message": {"type": "string", "description": "Message content"}
        },
        "required": ["channel", "message"]
    })

    def __init__(self):
        self.client = WebClient(token=os.getenv("SLACK_TOKEN"))

    def execute(self, args: dict[str, Any]) -> dict[str, Any]:
        try:
            response = self.client.chat_postMessage(
                channel=args["channel"],
                text=args["message"]
            )
            return {
                "ok": True,
                "data": {"message_ts": response["ts"]}
            }
        except SlackApiError as e:
            return {"ok": False, "error": str(e)}
```

---

### 8.2 模型抽象层

支持多种 LLM 提供商：

```python
# llm_client.py
class LLMClient(ABC):
    @abstractmethod
    async def stream_chat(
        self,
        messages: list[dict],
        model: str,
        tools: list[dict] | None = None
    ) -> AsyncIterator[dict]:
        pass

class OpenAIClient(LLMClient):
    async def stream_chat(self, messages, model, tools=None):
        async for chunk in openai.chat.completions.create(
            model=model,
            messages=messages,
            tools=tools,
            stream=True
        ):
            yield self._parse_chunk(chunk)

class AnthropicClient(LLMClient):
    async def stream_chat(self, messages, model, tools=None):
        # 转换为 Anthropic 格式
        async for chunk in anthropic.messages.stream(
            model=model,
            messages=self._convert_messages(messages),
            tools=self._convert_tools(tools)
        ):
            yield self._parse_chunk(chunk)

class LLMClientFactory:
    @staticmethod
    def create(provider: str) -> LLMClient:
        if provider == "openai":
            return OpenAIClient()
        elif provider == "anthropic":
            return AnthropicClient()
        elif provider == "google":
            return GoogleClient()
        else:
            raise ValueError(f"Unknown provider: {provider}")
```

---

### 8.3 配置中心

使用 Consul / Etcd 实现动态配置：

```python
class ConfigCenter:
    def __init__(self, consul_url: str):
        self.consul = consul.Consul(host=consul_url)
        self.cache = {}
        self.watchers = {}

    def get(self, key: str, default: Any = None) -> Any:
        """获取配置"""
        if key in self.cache:
            return self.cache[key]

        _, data = self.consul.kv.get(key)
        if data:
            value = json.loads(data['Value'].decode())
            self.cache[key] = value
            return value
        return default

    def watch(self, key: str, callback: Callable):
        """监听配置变化"""
        def watcher():
            index = None
            while True:
                index, data = self.consul.kv.get(key, index=index)
                if data:
                    new_value = json.loads(data['Value'].decode())
                    old_value = self.cache.get(key)

                    if new_value != old_value:
                        self.cache[key] = new_value
                        callback(key, new_value, old_value)

        thread = threading.Thread(target=watcher, daemon=True)
        thread.start()
        self.watchers[key] = thread

# 使用示例
config = ConfigCenter("consul:8500")

# 动态调整 API 超时时间
api_timeout = config.get("agent/api_timeout", 60)

# 监听配置变化
def on_timeout_changed(key, new_value, old_value):
    logger.info(f"API timeout changed: {old_value} → {new_value}")
    update_client_timeout(new_value)

config.watch("agent/api_timeout", on_timeout_changed)
```

---

## 9. 实施路线图

### 阶段一：数据持久化 (2-3 周)

**目标**: 解决数据丢失问题

- [ ] 引入 PostgreSQL 存储用户数据
- [ ] 引入 MongoDB 存储会话和消息
- [ ] 引入 Redis 作为缓存层
- [ ] 迁移现有内存数据结构

**交付物**:
- 数据库 Schema 设计文档
- 数据迁移脚本
- Repository 层实现
- 单元测试

---

### 阶段二：服务拆分 (3-4 周)

**目标**: 解耦服务，支持独立扩展

- [ ] 拆分 User Service
- [ ] 拆分 Session Service
- [ ] 拆分 Tool Service
- [ ] 实现服务间通信（gRPC）
- [ ] 配置服务发现（Consul）

**交付物**:
- 微服务架构图
- API 接口文档（gRPC .proto 文件）
- 服务部署脚本
- 集成测试

---

### 阶段三：API 网关 (2 周)

**目标**: 统一入口，增强安全性

- [ ] 部署 Kong API Gateway
- [ ] 实现 JWT 认证插件
- [ ] 实现 RBAC 授权
- [ ] 配置限流和熔断
- [ ] 集成监控（Prometheus）

**交付物**:
- Kong 配置文件
- 认证授权文档
- 监控大盘

---

### 阶段四：异步架构 (2-3 周)

**目标**: 提升并发性能

- [ ] 部署 RabbitMQ
- [ ] 改造工具执行为异步
- [ ] 实现事件驱动架构
- [ ] 配置死信队列和重试

**交付物**:
- 消息队列架构图
- 事件定义文档
- 性能测试报告

---

### 阶段五：缓存优化 (1-2 周)

**目标**: 降低数据库压力

- [ ] 实现多层缓存
- [ ] 配置 Redis Cluster
- [ ] 实现缓存预热
- [ ] 缓存监控和告警

**交付物**:
- 缓存策略文档
- 性能对比报告

---

### 阶段六：可扩展性 (2 周)

**目标**: 支持插件和多模型

- [ ] 实现插件系统
- [ ] 实现模型抽象层
- [ ] 配置中心（Consul）
- [ ] 文档和示例

**交付物**:
- 插件开发指南
- 模型接入文档

---

### 阶段七：生产部署 (2-3 周)

**目标**: 高可用部署

- [ ] Kubernetes 部署配置
- [ ] 配置自动扩缩容（HPA）
- [ ] 配置监控告警
- [ ] 灾难恢复方案
- [ ] 性能调优

**交付物**:
- K8s YAML 配置
- 运维手册
- 压力测试报告

---

## 总结

本文档提出了 MacJarvis 从单体应用到微服务架构的完整升级方案，涵盖：

1. **微服务化改造** - 拆分为 4 个核心服务
2. **数据持久化** - PostgreSQL + MongoDB + Redis
3. **分布式架构** - 服务发现、分布式锁、多数据中心
4. **API 网关** - Kong + JWT + RBAC
5. **消息队列** - RabbitMQ + 事件驱动
6. **缓存优化** - 多层缓存 + 防护机制
7. **可扩展性** - 插件系统 + 模型抽象

**预计周期**: 15-20 周（3.5-5 个月）

**团队建议**: 3-5 人（后端 2-3 人，DevOps 1 人，测试 1 人）

---

**下一步**: 请阅读其他优化文档，包括智能体功能、性能优化、安全性等方面的详细建议。
